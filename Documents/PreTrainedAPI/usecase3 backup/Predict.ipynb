{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf5385-0551-4f69-af95-7ef85b6ad670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import flask\n",
    "from flask import Flask, request, render_template\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "#from sklearn.externals import joblib\n",
    "import joblib \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "import google.cloud.automl_v1beta1.types as data_types\n",
    "import sys\n",
    " \n",
    "\n",
    "#os.chdir(r\"C:\\Users\\praful.turanur\\OneDrive - HCL Technologies Ltd\\Desktop\\AUTOML\\Flask\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "import sys\n",
    "\n",
    "#from google.cloud import automl_v1beta1\n",
    "#from google.cloud.automl_v1beta1.proto import service_pb2\n",
    "\n",
    "\n",
    "\n",
    "# 'content' is base-64-encoded image data.\n",
    "def get_prediction(content, project_id, model_id):\n",
    "    prediction_client = automl_v1beta1.PredictionServiceClient()\n",
    "\n",
    "    name = 'projects/{}/locations/us-central1/models/{}'.format(project_id, model_id)\n",
    "    payload = {'image': {'image_bytes': content }}\n",
    "    params = {}\n",
    "#    request = prediction_client.predict(name, payload)\n",
    "    request = prediction_client.predict(name=name, payload=payload, params=params)\n",
    "    return request  # waits till request is returned\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#  file_path = sys.argv[1]\n",
    "#  project_id = sys.argv[2]\n",
    "#  model_id = sys.argv[3]\n",
    "#    file_path = \"img_35.jpg\"\n",
    "project_id = \"gebu-data-ml-day0-01-333910\"\n",
    "model_id = \"ICN6699225391992668160\" \n",
    "\n",
    "#    with open(file_path, 'rb') as ff:\n",
    "#        content = ff.read()\n",
    "\n",
    "#    print (get_prediction(content, project_id, model_id))\n",
    "\n",
    "#def load_image(img_path):\n",
    "\n",
    "#    img = load_img(img_path, target_size=(224, 224))\n",
    "#    img_tensor = img_to_array(img)                    # (height, width, channels)\n",
    "#    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "#    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "#    return img_tensor\n",
    "\n",
    "# =============================================================================\n",
    "# def prediction(img_path):\n",
    "#     new_image = load_image(img_path)\n",
    "#     model = joblib.load(\"usecase3model.pkl\")\n",
    "#     pred = model.predict(new_image)\n",
    "#     return pred\n",
    "# =============================================================================\n",
    "    \n",
    "\n",
    "\t\n",
    "# @app.route('/')\n",
    "# def index():\n",
    "# \treturn render_template('image_index.html')\n",
    "\n",
    "# @app.route('/predict', methods = ['POST'])  \n",
    "# def predict():  \n",
    "#     if request.method == 'POST':  \n",
    "#         file = request.files['file']  \n",
    "#         filename = file.filename\n",
    "# #        file_path = os.path.join(r'C:\\Users\\praful.turanur\\OneDrive - HCL Technologies Ltd\\Desktop\\AUTOML\\Flask', filename)\n",
    "#         file_path = os.path.join(r'ML_Specialization_UseCase_3/', filename)\n",
    "#     #slashes should be handeled properly\n",
    "#         file.save(file_path)\n",
    "# #        return \"Successfully uploaded the file at {}\".format(file_path)\n",
    "#         with open(file_path, 'rb') as ff:\n",
    "#             content = ff.read()\n",
    "# #        result = prediction(file_path)\n",
    "#         result = get_prediction(content, project_id, model_id)\n",
    "#         return \"the prediction is {}\".format(result)\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# #    app.run()\n",
    "#     app.run(host='127.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9af54a-3586-44e9-bbe0-6f08041ac030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "payload {\n",
      "  annotation_spec_id: \"3119297445570281472\"\n",
      "  classification {\n",
      "    score: 1.0\n",
      "  }\n",
      "  display_name: \"6\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from google.cloud import automl_v1beta1\n",
    "from google.cloud.automl_v1beta1.proto import service_pb2\n",
    "\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "import google.cloud.automl_v1beta1.types as data_types\n",
    "\n",
    "# 'content' is base-64-encoded image data.\n",
    "def get_prediction(content, project_id, model_id):\n",
    "    prediction_client = automl_v1beta1.PredictionServiceClient()\n",
    "\n",
    "    name = 'projects/{}/locations/us-central1/models/{}'.format(project_id, model_id)\n",
    "    payload = {'image': {'image_bytes': content }}\n",
    "    params = {}\n",
    "#    request = prediction_client.predict(name, payload)\n",
    "    request = prediction_client.predict(name=name, payload=payload, params=params)\n",
    "    return request  # waits till request is returned\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "\treturn render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods = ['POST'])  \n",
    "def predict():  \n",
    "    if request.method == 'POST':  \n",
    "        file = request.files['file']  \n",
    "        filename = file.filename\n",
    "        file_path = os.path.join(r'C:\\Users\\praful.turanur\\OneDrive - HCL Technologies Ltd\\Desktop\\AUTOML\\Flask', filename)                       #slashes should be handeled properly\n",
    "        file.save(file_path)\n",
    "#        return \"Successfully uploaded the file at {}\".format(file_path)\n",
    "        result = prediction(file_path)\n",
    "        return \"the prediction is {}\".format(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#  file_path = sys.argv[1]\n",
    "#  project_id = sys.argv[2]\n",
    "#  model_id = sys.argv[3]\n",
    "    file_path = \"img_35.jpg\"\n",
    "    project_id = \"gebu-data-ml-day0-01-333910\"\n",
    "    model_id = \"ICN6699225391992668160\" \n",
    "\n",
    "    with open(file_path, 'rb') as ff:\n",
    "        content = ff.read()\n",
    "\n",
    "    print (get_prediction(content, project_id, model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95feeb-2e0d-4ba3-bf06-27f491254791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
